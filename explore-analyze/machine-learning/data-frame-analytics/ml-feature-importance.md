---
applies:
  stack:
  serverless:
mapped_pages:
  - https://www.elastic.co/guide/en/machine-learning/current/ml-feature-importance.html
---

# Feature importance [ml-feature-importance]

{{feat-imp-cap}} values indicate which fields had the biggest impact on each prediction that is generated by {{classification}} or {{regression}} analysis. Each {{feat-imp}} value has both a magnitude and a direction (positive or negative), which indicate how each field (or *feature* of a data point) affects a particular prediction.

The purpose of {{feat-imp}} is to help you determine whether the predictions are sensible. Is the relationship between the dependent variable and the important features supported by your domain knowledge? The lessons you learn about the importance of specific features might also affect your decision to include them in future iterations of your trained model.

You can see the average magnitude of the {{feat-imp}} values for each field across all the training data in {{kib}} or by using the [get trained model API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-ml-get-trained-models). For example, {{kib}} shows the total feature importance for each field in {{regression}} or binary {{classanalysis}} results as follows:

:::{image} ../../../images/machine-learning-flights-regression-total-importance.jpg
:alt: Total {{feat-imp}} values for a {{regression}} {dfanalytics-job} in {kib}
:class: screenshot
:::

If the {{classanalysis}} involves more than two classes, {{kib}} uses colors to show how the impact of each field varies by class. For example:

:::{image} ../../../images/machine-learning-diamonds-classification-total-importance.png
:alt: Total {{feat-imp}} values for a {{classification}} {dfanalytics-job} in {kib}
:class: screenshot
:::

You can also examine the feature importance values for each individual prediction. In {{kib}}, you can see these values in JSON objects or decision plots. For {{reganalysis}}, each decision plot starts at a shared baseline, which is the average of the prediction values for all the data points in the training data set. When you add all of the feature importance values for a particular data point to that baseline, you arrive at the numeric prediction value. If a {{feat-imp}} value is negative, it reduces the prediction value. If a {{feat-imp}} value is positive, it increases the prediction value. For example:

:::{image} ../../../images/machine-learning-flights-regression-decision-plot.png
:alt: Feature importance values for a {{regression}} {dfanalytics-job} in {kib}
:class: screenshot
:::

For {{classanalysis}}, the sum of the {{feat-imp}} values approximates the predicted logarithm of odds for each data point. The simplest way to understand {{feat-imp}} in the context of {{classanalysis}} is to look at the decision plots in {{kib}}. For each data point, there is a chart which shows the relative impact of each feature on the prediction probability for that class. This information helps you to understand which features reduces or increase the prediction probability. For example:

:::{image} ../../../images/machine-learning-flights-classification-decision-plot.png
:alt: A decision plot in {{kib}}for a {{classification}} {dfanalytics-job}
:class: screenshot
:::

By default, {{feat-imp}} values are not calculated. To generate this information, when you create a {{dfanalytics-job}} you must specify the `num_top_feature_importance_values` property. For example, see [Performing {{reganalysis}} in the sample flight data set](ml-dfa-regression.md#performing-regression) and [Performing {{classanalysis}} in the sample flight data set](ml-dfa-classification.md#performing-classification).

The {{feat-imp}} values are stored in the {{ml}} results field for each document in the destination index. The number of {{feat-imp}} values for each document might be less than the `num_top_feature_importance_values` property value. For example, it returns only features that had a positive or negative effect on the prediction.
