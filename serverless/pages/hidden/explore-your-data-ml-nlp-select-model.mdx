---
# slug: /serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/select-model
title: Select a trained model
# description: Description to be written
tags: [ 'serverless', 'elasticsearch', 'tbd' ]
---

<DocBadge template="technical preview" />
Per the 
<DocLink slug="/serverless/elasticsearch/explore-your-data-ml-nlp">Overview</DocLink>, 
there are multiple ways that you can use NLP features within the ((stack)). 
After you determine which type of NLP task you want to perform, you must choose 
an appropriate trained model. 

The simplest method is to use a model that has already been fine-tuned for the
type of analysis that you want to perform. For example, there are models and
data sets available for specific NLP tasks on
[Hugging Face](https://huggingface.co/models). These instructions assume you're
using one of those models and do not describe how to create new models. For the
current list of supported model architectures, refer to 
<DocLink slug="/serverless/elasticsearch/explore-your-data-ml-nlp/model-reference">Compatible third party NLP models</DocLink>.

If you choose to perform ((lang-ident)) by using the `lang_ident_model_1` that is 
provided in the cluster, no further steps are required to import or deploy the 
model. You can skip to using the model in 
<DocLink slug="/serverless/elasticsearch/explore-your-data-ml-nlp/inference">ingestion pipelines</DocLink>.