---
# slug: /serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/import-model
title: Import the trained model and vocabulary
# description: Description to be written
tags: [ 'serverless', 'elasticsearch', 'tbd' ]
---

<DocBadge template="technical preview" />
<DocCallOut title="Important" color="warning">
If you want to install a trained model in a restricted or closed
network, refer to
[these instructions](((eland-docs))/machine-learning.html#ml-nlp-pytorch-air-gapped).
</DocCallOut>

After you choose a model, you must import it and its tokenizer vocabulary to
your cluster. When you import the model, it must be chunked and imported one
chunk at a time for storage in parts due to its size.

<DocCallOut title="Note">
Trained models must be in a TorchScript representation for use with
((stack-ml-features)).
</DocCallOut>

[Eland](https://github.com/elastic/eland) is an ((es)) Python client that
provides a simple script to perform the conversion of Hugging Face transformer
models to their TorchScript representations, the chunking process, and upload to
((es)); it is therefore the recommended import method. You can either install
the Python Eland client on your machine or use a Docker image to build Eland and
run the model import script.


## Import with the Eland client installed

1. Install the [Eland Python client](((eland-docs))/installation.html) with
    PyTorch extra dependencies.

    ```shell
    python -m pip install 'eland[pytorch]'
    ```
    {/* NOTCONSOLE */}

1. Run the `eland_import_hub_model` script to download the model from Hugging
    Face, convert it to TorchScript format, and upload to the ((es)) cluster.
    For example:

    {/* NOTCONSOLE */}
    ```shell
    eland_import_hub_model
    -u <username> -p <password> \  [^2]
    ```
    [^1]: Specify the Elastic Cloud identifier. Alternatively, use `--url`.
    [^2]: Provide authentication details to access your cluster. Refer to
    <DocLink slug="/serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/import-model" section="authentication-methods">Authentication methods</DocLink> to learn more.
    [^3]: Specify the identifier for the model in the Hugging Face model hub.
    [^4]: Specify the type of NLP task. Supported values are `fill_mask`, `ner`,
    `text_classification`, `text_embedding`, and `zero_shot_classification`.

For more details, refer to
https://www.elastic.co/guide/en/elasticsearch/client/eland/current/machine-learning.html#ml-nlp-pytorch.


## Import with Docker

<DocCallOut title="Important" color="warning">
To use the Docker container, you need to clone the Eland repository:
https://github.com/elastic/eland
</DocCallOut>

If you want to use Eland without installing it, clone the Eland repository and
from the root directory run the following to build the Docker image:

```bash
$ docker build -t elastic/eland .
```

You can now use the container interactively:

```bash
$ docker run -it --rm --network host elastic/eland
```

The `eland_import_hub_model` script can be run directly in the docker command:

```bash
docker run -it --rm elastic/eland \
    eland_import_hub_model \
      --url $ELASTICSEARCH_URL \
      --hub-model-id elastic/distilbert-base-uncased-finetuned-conll03-english \
      --start
```

Replace the `$ELASTICSEARCH_URL` with the URL for your ((es)) cluster. Refer to
<DocLink slug="/serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/import-model" section="authentication-methods">Authentication methods</DocLink>
to learn more.


## Authentication methods

The following authentication options are available when using the import script:

* username/password authentication (specified with the `-u` and `-p` options):

```bash
eland_import_hub_model --url https://<hostname>:<port> -u <username> -p <password> ...
```

* username/password authentication (embedded in the URL):

    ```bash
    eland_import_hub_model --url https://<user>:<password>@<hostname>:<port> ...
    ```

* API key authentication:

    ```bash
    eland_import_hub_model --url https://<hostname>:<port> --es-api-key <api-key> ...
    ```