= Import the trained model and vocabulary

// :keywords: serverless, elasticsearch, tbd

preview:[]

[IMPORTANT]
====
If you want to install a trained model in a restricted or closed
network, refer to
{eland-docs}/machine-learning.html#ml-nlp-pytorch-air-gapped[these instructions].
====

After you choose a model, you must import it and its tokenizer vocabulary to
your cluster. When you import the model, it must be chunked and imported one
chunk at a time for storage in parts due to its size.

[NOTE]
====
Trained models must be in a TorchScript representation for use with
{stack-ml-features}.
====

https://github.com/elastic/eland[Eland] is an {es} Python client that
provides a simple script to perform the conversion of Hugging Face transformer
models to their TorchScript representations, the chunking process, and upload to
{es}; it is therefore the recommended import method. You can either install
the Python Eland client on your machine or use a Docker image to build Eland and
run the model import script.

[discrete]
[[import-with-the-eland-client-installed]]
== Import with the Eland client installed

. Install the {eland-docs}/installation.html[Eland Python client] with
PyTorch extra dependencies.
+
[source,shell]
----
python -m pip install 'eland[pytorch]'
----
+
// NOTCONSOLE
. Run the `eland_import_hub_model` script to download the model from Hugging
Face, convert it to TorchScript format, and upload to the {es} cluster.
For example:
+
// NOTCONSOLE
+
[source,shell]
----
eland_import_hub_model
-u <username> -p <password> \   <2>
----
+
<1> Specify the Elastic Cloud identifier. Alternatively, use `--url`.
+
<2> Provide authentication details to access your cluster. Refer to
https://www.elastic.co/docs/current/serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/import-model[Authentication methods] to learn more.
+
<3> Specify the identifier for the model in the Hugging Face model hub.
+
<4> Specify the type of NLP task. Supported values are `fill_mask`, `ner`,
`text_classification`, `text_embedding`, and `zero_shot_classification`.

For more details, refer to
https://www.elastic.co/guide/en/elasticsearch/client/eland/current/machine-learning.html#ml-nlp-pytorch[https://www.elastic.co/guide/en/elasticsearch/client/eland/current/machine-learning.html#ml-nlp-pytorch].

[discrete]
[[import-with-docker]]
== Import with Docker

[IMPORTANT]
====
To use the Docker container, you need to clone the Eland repository:
https://github.com/elastic/eland[https://github.com/elastic/eland]
====

If you want to use Eland without installing it, clone the Eland repository and
from the root directory run the following to build the Docker image:

[source,bash]
----
$ docker build -t elastic/eland .
----

You can now use the container interactively:

[source,bash]
----
$ docker run -it --rm --network host elastic/eland
----

The `eland_import_hub_model` script can be run directly in the docker command:

[source,bash]
----
docker run -it --rm elastic/eland \
    eland_import_hub_model \
      --url $ELASTICSEARCH_URL \
      --hub-model-id elastic/distilbert-base-uncased-finetuned-conll03-english \
      --start
----

Replace the `$ELASTICSEARCH_URL` with the URL for your {es} cluster. Refer to
https://www.elastic.co/docs/current/serverless/elasticsearch/explore-your-data-ml-nlp/deploy-trained-models/import-model[Authentication methods]
to learn more.

[discrete]
[[authentication-methods]]
== Authentication methods

The following authentication options are available when using the import script:

* username/password authentication (specified with the `-u` and `-p` options):

[source,bash]
----
eland_import_hub_model --url https://<hostname>:<port> -u <username> -p <password> ...
----

* username/password authentication (embedded in the URL):
+
[source,bash]
----
eland_import_hub_model --url https://<user>:<password>@<hostname>:<port> ...
----
* API key authentication:
+
[source,bash]
----
eland_import_hub_model --url https://<hostname>:<port> --es-api-key <api-key> ...
----
