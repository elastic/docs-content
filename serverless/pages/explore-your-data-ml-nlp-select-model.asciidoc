= Select a trained model

// :keywords: serverless, elasticsearch, tbd

Per the
<<elasticsearch-explore-your-data-ml-nlp,Overview>>,
there are multiple ways that you can use NLP features within the {stack}.
After you determine which type of NLP task you want to perform, you must choose
an appropriate trained model.

The simplest method is to use a model that has already been fine-tuned for the
type of analysis that you want to perform. For example, there are models and
data sets available for specific NLP tasks on
https://huggingface.co/models[Hugging Face]. These instructions assume you're
using one of those models and do not describe how to create new models. For the
current list of supported model architectures, refer to
<<elasticsearch-explore-your-data-ml-nlp-model-reference,Compatible third party NLP models>>.

If you choose to perform {lang-ident} by using the `lang_ident_model_1` that is
provided in the cluster, no further steps are required to import or deploy the
model. You can skip to using the model in
<<elasticsearch-explore-your-data-ml-nlp-inference,ingestion pipelines>>.
