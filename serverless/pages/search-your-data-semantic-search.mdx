---
slug: /serverless/elasticsearch/elasticsearch/reference/semantic-search
title: Semantic search
description: Find data based on the intent and contextual meaning of a search query with semantic search
tags: ['elasticsearch', 'elser', 'semantic search']
---

<DocBadge template="technical preview" />

import DeployNlpModelWidget from '../partials/deploy-nlp-model-widget.mdx'
import FieldMappingsWidget from '../partials/field-mappings-widget.mdx'
import GenerateEmbeddingsWidget from '../partials/generate-embeddings-widget.mdx'
import SearchWidget from '../partials/search-widget.mdx'
import HybridSearchWidget from '../partials/hybrid-search-widget.mdx'

<div id="semantic-search"></div>

Semantic search is a search method that helps you find data based on the intent
and contextual meaning of a search query, instead of a match on query terms
(lexical search).

((es)) provides semantic search capabilities using [natural
language processing (NLP)](((ml-docs))/ml-nlp.html) and vector search. Deploying an NLP model to ((es))
enables it to extract text embeddings out of text. Embeddings are vectors that
provide a numeric representation of a text. Pieces of content with similar
meaning have similar representations.

<div id="semantic-search-diagram"></div>

<div style={{ textAlign: "center" }}><DocImage url="../images/vector-search-oversimplification.png" alt="A simplified representation of encoding textual concepts as vectors" /></div>
_A simplified representation of encoding textual concepts as vectors_

At query time, ((es)) can use the same NLP model to convert a query into
embeddings, enabling you to find documents with similar text embeddings.

This guide shows you how to implement semantic search with ((es)), from selecting
an NLP model, to writing queries.

<div id="semantic-search-select-nlp-model"></div>

## Select an NLP model

((es)) offers the usage of a
[wide range of NLP models](((ml-docs))/ml-nlp-model-ref.html#ml-nlp-model-ref-text-embedding),
including both dense and sparse vector models. Your choice of the language model
is critical for implementing semantic search successfully.

While it is possible to bring your own text embedding model, achieving good
search results through model tuning is challenging. Selecting an appropriate
model from our third-party model list is the first step. Training the model on
your own data is essential to ensure better search results than using only BM25.
However, the model training process requires a team of data scientists and ML
experts, making it expensive and time-consuming.

To address this issue, Elastic provides a pre-trained representational model
called [Elastic Learned Sparse EncodeR (ELSER)](((ml-docs))/ml-nlp-elser.html).
ELSER, currently available only for English, is an out-of-domain sparse vector
model that does not require fine-tuning. This adaptability makes it suitable for
various NLP use cases out of the box. Unless you have a team of ML specialists,
it is highly recommended to use the ELSER model.

In the case of sparse vector representation, the vectors mostly consist of zero
values, with only a small subset containing non-zero values. This representation
is commonly used for textual data. In the case of ELSER, each document in an
index and the query text itself are represented by high-dimensional sparse
vectors. Each non-zero element of the vector corresponds to a term in the model
vocabulary. The ELSER vocabulary contains around 30000 terms, so the sparse
vectors created by ELSER contain about 30000 values, the majority of which are
zero. Effectively the ELSER model is replacing the terms in the original query
with other terms that have been learnt to exist in the documents that best match
the original search terms in a training dataset, and weights to control how
important each is.

<div id="semantic-search-deploy-nlp-model"></div>

## Deploy the model

After you decide which model you want to use for implementing semantic search,
you need to deploy the model in ((es)).

<DeployNlpModelWidget />

<div id="semantic-search-field-mappings"></div>

## Map a field for the text embeddings

Before you start using the deployed model to generate embeddings based on your
input text, you need to prepare your index mapping first. The mapping of the
index depends on the type of model.

<FieldMappingsWidget />

<div id="semantic-search-generate-embeddings"></div>

## Generate text embeddings

Once you have created the mappings for the index, you can generate text
embeddings from your input text. This can be done by using an
[ingest pipeline](((ref))/ingest.html) with an [inference processor](((ref))/inference-processor.html).
The ingest pipeline processes the input data and indexes it into the destination
index. At index time, the inference ingest processor uses the trained model to
infer against the data ingested through the pipeline. After you created the
ingest pipeline with the inference processor, you can ingest your data through
it to generate the model output.

<GenerateEmbeddingsWidget />

Now it is time to perform semantic search!

<div id="semantic-search-search"></div>

## Search the data

Depending on the type of model you have deployed, you can query rank features
with a text expansion query, or dense vectors with a kNN search.

<SearchWidget />

<div id="semantic-search-hybrid-search"></div>

## Beyond semantic search with hybrid search

In some situations, lexical search may perform better than semantic search. For
example, when searching for single words or IDs, like product numbers.

Combining semantic and lexical search into one hybrid search request using
[reciprocal rank fusion](((ref))/rrf.html) provides the best of both worlds. Not only that,
but hybrid search using reciprocal rank fusion [has been shown to perform better
in general](((blog-ref))improving-information-retrieval-elastic-stack-hybrid).

<HybridSearchWidget />

<div id="semantic-search-read-more"></div>

## Read more

* Tutorials:
    * <DocLink slug="/serverless/elasticsearch/elasticsearch/reference/semantic-search-elser">Semantic search with ELSER</DocLink>
    * [Semantic search with the msmarco-MiniLM-L-12-v3 sentence-transformer model](((ml-docs))/ml-nlp-text-emb-vector-search-example.html)
* Blogs:
    * [Introducing Elastic Learned Sparse Encoder: Elastic's AI model for semantic search](((blog-ref))may-2023-launch-sparse-encoder-ai-model)
    * [How to get the best of lexical and AI-powered search with Elastic's vector database](((blog-ref))lexical-ai-powered-search-elastic-vector-database)
    * Information retrieval blog series:
        * [Part 1: Steps to improve search relevance](((blog-ref))improving-information-retrieval-elastic-stack-search-relevance)
        * [Part 2: Benchmarking passage retrieval](((blog-ref))improving-information-retrieval-elastic-stack-benchmarking-passage-retrieval)
        * [Part 3: Introducing Elastic Learned Sparse Encoder, our new retrieval model](((blog-ref))may-2023-launch-information-retrieval-elasticsearch-ai-model)
        * [Part 4: Hybrid retrieval](((blog-ref))improving-information-retrieval-elastic-stack-hybrid)
* Interactive examples:
    * The [`elasticsearch-labs`](https://github.com/elastic/elasticsearch-labs) repo contains a number of interactive semantic search examples in the form of executable Python notebooks, using the ((es)) Python client.

{/* The include that was here is another page */}
