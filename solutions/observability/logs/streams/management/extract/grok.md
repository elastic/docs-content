---
applies_to:
    serverless: preview
---
# Grok processor [streams-grok-processor]

The grok processor is used to parse unstructured log messages and extract fields from them. It uses a set of predefined patterns to match the log messages and extract the fields. The grok processor is very powerful and can be used to parse a wide variety of log formats.

You can provide multiple patterns to the Grok processor. The Grok processor will try to match the log message against each pattern in the order they are provided. If a pattern matches, the fields will be extracted and the remaining patterns will not be used. If a pattern does not match, the grok processor will try the next pattern. If no patterns match, the grok processor will fail and you can troubleshoot the issue. See below for more information.
It is recommended to start with the most common patterns first and then add more specific patterns later. This will help to reduce the number of runs the grok processor has to do and will improve the performance of the pipeline.

This functionality uses the {{es}} grok pipeline processor. Refer to [grok processor](elasticsearch://reference/enrich-processor/grok-processor.md) in the {{es}} docs for more information.

The grok processor uses a set of predefined patterns to match the log messages and extract the fields. The patterns are defined in the TODO.
In addition you can also define your own pattern definitions by expanding the `Optional fields` section. This will allow you to define your own patterns and use them in the grok processor.
The patterns are defined in the following format:
```
{
  "MY_DATE": "%{YEAR}-%{MONTHNUM}-%{MONTHDAY}"
}
```
Where `MY_DATE` is the name of the pattern.
The above pattern can then be used in the processor
```
%{MY_DATE:date}
```

## Generate Patterns [streams-grok-patterns]
Requires an LLM Connector to be configured. TOOD: Elastic LLM?
Instead of writing the grok patterns by hand, you can use the **Generate Patterns** button to generate the patterns for you.

![generated patterns](<../patterns.png>)

Patterns can be accepted by clicking the plus icon next to the pattern. This will add the pattern to the list of patterns to be used in the grok processor.

### How does the pattern generation work? [streams-grok-pattern-generation]
Under the hood, the 100 samples on the right hand side are grouped into categories of similar messages. For each category, a grok pattern is generated by sending a few samples to the LLM. Matching patterns are then shown in the UI.

:::{note}
This can incur additional costs, depending on the LLM connector you are using. Typically a single interation uses between 1000 and 5000 tokens, depending on the number of identified categories and the length of the messages.
:::